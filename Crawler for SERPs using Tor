#!/usr/bin/python

import time
import xml.dom.minidom
import urllib2
import HTMLParser
import re
from htmlentitydefs import name2codepoint
from htmldom import htmldom
from TorCtl import TorCtl


keywords = ["jump",'awer', 'wwwww' , 'awdd','jumping','trye', "your+partner+mingpao", "jumping", "jump+chine","dawdaw","jump+china","jummp","minpao","ming"]
domain = "jump.mingpao.com"
engines = ["gr","com"]
headers={'User-agent':'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7',
    'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language':'en-US,en;q=0.8',
    'Cache-Control':'max-age=0',
    'Connection':'keep-alive'
}


def renew_connection():
    conn = TorCtl.connect(controlAddr="127.0.0.1", controlPort=9051, passphrase="########")
    conn.send_signal("NEWNYM")
    conn.close()


def get_page(engine,keyword,page):
    time.sleep(4)
    def _set_urlproxy():
        proxy_support = urllib2.ProxyHandler({"http" : "127.0.0.1:8118"})
        opener = urllib2.build_opener(proxy_support)
        urllib2.install_opener(opener)
    _set_urlproxy()

    url = 'https://www.google.%s/search?q=%s&start=%s'%(engine,keyword,page)
    request=urllib2.Request(url, None, headers)
    response = urllib2.urlopen(request).read()

    response = str(response)
    response = re.sub('<b>|</b>','', response)
    return response


def get_serp(engine,keyword,domain):
    list = []
    serp = 1
    #renew_connection()
    for page in range(0,5):
        response = get_page(engine,keyword,page*10)

        dom = htmldom.HtmlDom().createDom(response)
        for i in range(0,10):
            if (dom.find( "cite" )[i].text()):
                list.append(dom.find( "cite" )[i].text())
                if str(dom.find( "cite" )[i].text()).startswith(domain):
                    return serp
                else:
                    serp += 1
            else:
                return "Could not determine serp"    
    return "Not in 50"


def get_keywords_serps(engine,keywords,domain):
    serps = []
    count = 0
    for keyword in keywords:
        count += 1
        serp = get_serp(engine,keyword,domain)
        serps.append([keyword, serp])
        if count == 10:
            renew_connection()
            count = 0
    return serps


engines_serps = []
for engine in engines:
    serps = get_keywords_serps(engine,keywords,domain)
    engines_serps.append(serps)

print engines_serps


